"Metaphor Preservation in Machine Translation and Paraphrasing",,2023,"|PAPER:https://vilda.net/papers/metaphor_preservation.pdf|CODE:https://github.com/zouharvi/metaphor-preservation","Metaphors play a crucial role in human communication. Improving the handling of metaphors in NLP will enhance the quality and accuracy of cross-lingual communication, benefiting various applications such as multilingual chatbots, localization, and cross-cultural understanding. This paper reports an evaluation that focuses on the analysis of metaphor presence and preservation in machine-translated and paraphrased texts. The results suggest that textual language models do not have access to the metaphorical meaning and do not fully understand this literal device. They are not sensitive to the subtle differences between various paraphrases but can be used for the rudimentary analysis of machine translation output, which varies greatly with respect to metaphor preservation.","metaphor_preservation.png"
"Ryanize bib",,2023,"|TOOL:https://vilda.net/s/ryanize-bib|CODE:https://github.com/zouharvi/ryanize-bib","Tool to check for common BibTeX best practice violations","ryanize_bib.png"
"Poetry, Songs, Literature, Legalese and Translationese",,2023,"|PAPER:https://vilda.net/papers/automated_sentence_complexity_perspective.pdf|CODE:https://github.com/zouharvi/genre-complexity","Although non-trivial to measure, natural texts come in varying complexities. As a result, multiple domains and genres can be compared based on their complexities. In this study, focused on measuring sentence complexity, I use automated methods of complexity estimation to compare poetry, natural prose, literary prose and machine and human translation. The conclusion is that old poetry and old literature is more complex than their modern counterparts, as measured by language model complexity, Flesch Reading Ease and syntactic depth. Furthermore, we observe that machine translations are faithful to human references in terms of sentence complexity, which is a positive result for the translation industry. Most importantly, this paper discusses the reason for different complexities across varying text domains, which is framed as ''form (complexity) follows function and aesthetics with least effort.''","genre_complexity.png"
"Stolen Subwords",,2023,"|PAPER:https://arxiv.org/abs/2401.16055|CODE:https://github.com/zouharvi/stolen-subwords","In learning-based functionality stealing, the attacker is trying to build a local model based on the victim's outputs. The attacker has to make choices regarding the local model's architecture, optimization method and, specifically for NLP models, subword vocabulary, such as BPE. On the machine translation task, we explore (1) whether the choice of the vocabulary plays a role in model stealing scenarios and (2) if it is possible to extract the victim's vocabulary. We find that the vocabulary itself does not have a large effect on the local model's performance. Given gray-box model access, it is possible to collect the victim's vocabulary by collecting the outputs (detokenized subwords on the output). The results of the minimum effect of vocabulary choice are important more broadly for black-box knowledge distillation.","stolen_subwords.png"
"Multimodal Shannon Game with Images","Vilém Zouhar,<sup>=</sup> Sunit Bhattacharya,<sup>=</sup> Ondřej Bojar","Preprint 2022","|PAPER:https://arxiv.org/abs/2303.11192|CODE:https://github.com/zouharvi/mmsg|DEMO:https://vilda.net/s/mmsg/?uid=demo","The Shannon game has long been used as a thought experiment in linguistics and NLP, asking participants to guess the next letter in a sentence based on its preceding context. We extend the game by introducing an optional extra modality in the form of image information. To investigate the impact of multimodal information in this game, we use human participants and a language model (LM, GPT-2). We show that the addition of image information improves both self-reported confidence and accuracy for both humans and LM. Certain word classes, such as nouns and determiners, benefit more from the additional modality information. The priming effect in both humans and the LM becomes more apparent as the context size (extra modality information + sentence context) increases. These findings highlight the potential of multimodal information in improving language understanding and modeling.","mmsg.png"
"ÚFAL Bilingual scientific abstracts corpus","Rudolf Rosa, Vilém Zouhar",2022,"|DATASET:https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4922|CODE:https://github.com/ufal/bilingual-abstracts-corpus","This is a parallel corpus of Czech and mostly English abstracts of scientific papers and presentations published by authors from the Institute of Formal and Applied Linguistics, Charles University in Prague. For each publication record, the authors are obliged to provide both the original abstract (in Czech or English), and its translation (English or Czech) in the internal Biblio system. The data was filtered for duplicates and missing entries, ensuring that every record is bilingual. Additionally, records of published papers which are indexed by SemanticScholar contain the respective link. The dataset was created from September 2022 image of the Biblio database and is stored in JSONL format, with each line corresponding to one record.","ufal_bilingual_dataset.png"
"Stroop Effect in Multi-Modal Sight Translation","Sunit Bhattacharya, Vilém Zouhar, Věra Kloudová, Ondřej Bojar","Preprint 2022","|PAPER:https://psyarxiv.com/5qdgr|CODE:https://github.com/ufal/eyetracked-multi-modal-translation","This study investigates the human translation process from English to Czech in a multi-modal scenario (images) using reaction times. We make a distinction between ambiguous and unambiguous sentences where in the former, more information would be needed in order to make a proper translation (e.g. gender of the subject). Simultaneously, we also provide visual aid to help in disambiguation, which is necessary for the ambiguous sentences. We confirm that ambiguous sentences take longer to translate and the provision of disambiguating visual aid slows the translation process. When provided with an unrelated visual aid, humans are able to recognize and spend less time on it but still significantly more than in other conditions. These findings are a clear manifestation of the Stroop effect (longer processing times for incongruent combinations).","eyetracked_multimodal_translation_1.png"
"Machine Translate",,2022,"|LINK:https://machinetranslate.org/|CODE:https://github.com/machinetranslate/machinetranslate.org","Open resources and community for machine translation",
"Random Strum Pattern Generator",,2022,"|TOOL:https://vilda.net/s/rsp/","Little tool to generate practice guitar strum patterns.","rsp.png"
"Fusing Sentence Embeddings Into LSTM-based Autoregressive Language Models","Vilém Zouhar, Marius Mosbach, Dietrich Klakow","Preprint 2021","|PAPER:https://arxiv.org/abs/2208.02402|CODE:https://github.com/zouharvi/sentence-embd-fusion","Although masked language models are highly performant and widely adopted by NLP practitioners, they can not be easily used for autoregressive language modelling (next word prediction and sequence probability estimation). We present an LSTM-based autoregressive language model which uses prefix embeddings (from a pretrained masked language model) via fusion (e.g. concatenation) to obtain a richer context representation for language modelling. We find that fusion helps reliably in lowering the perplexity (16.74 → 15.80), which is even preserved after a transfer to a dataset from a different domain than the training data. We also evaluate the best-performing fusion model by correlating its next word surprisal estimates with human reading times. Contradicting our expectation, and despite the improvement in perplexity overall, the correlation remains the same as for the baseline model. Lastly, while we focus on language models pre-trained on text as the sources for the fusion, our approach can be possibly extended to fuse any information represented as a fixed-size vector into an auto-regressive language model. These include e.g. sentence external information retrieved for a knowledge base or representations of multi-modal encoders.","sentence_embd_fusion.png"
"EMMT: An eye-tracking, EEG and audio corpus for multi-modal reading and translation","Sunit Bhattacharya, Vilém Zouhar, Věra Kloudová, Ondřej Bojar","Preprint 2021","|PAPER:https://arxiv.org/abs/2204.02905|CODE:https://github.com/ufal/eyetracked-multi-modal-translation","We present the Eyetracked Multi-Modal Translation (EMMT) corpus, a dataset containing monocular eye movement recordings, audio and 4-electrode electroencephalogram (EEG) data of 43 participants. The objective was to collect cognitive signals as responses of participants engaged in a number of language intensive tasks involving different text-image stimuli settings when translating from English to Czech.Each participant was exposed to 32 text-image stimuli pairs and asked to (1) read the English sentence, (2) translate it into Czech, (3) consult the image, (4) translate again, either updating or repeating the previous translation. The text stimuli consisted of 200 unique sentences with 616 unique words coupled with 200 unique images as the visual stimuli.The recordings were collected over a two week period and all the participants included in the study were Czech natives with strong English skills. Due to the nature of the tasks involved in the study and the relatively large number of participants involved, the corpus is well suited for research in Translation Process Studies, Cognitive Sciences among other disciplines.","eyetracked_multimodal_translation_2.png"
"Deep Molecule QSPR","Nikola Kalábová, Vilém Zouhar",2021,"|CODE:https://github.com/zouharvi/deep-molecule-qspr","The goal of Deep Molecule QSPR (Quantitative Structure-Property Relationships) is to predict several key temperature points of a molecule. The input is a graph of the given molecule and the output a single number: the predicted boiling or melting point. The model uses graph-informed feature extraction, which is then used as an input to simple feed-forward neural networks and achieves a significant performance, or a simple linear regression model, which allows for a degree of explainability. The novel contributions include the feature extraction itself (various atom weighting and structural functions), applicability to a wide range of molecule classes and the combination with a neural network to gain better performance compared to widely used linear regression models.",
"Statistical Natural Language Processing Tutorials","Vilém Zouhar, Awantee Deshpande, Julius Steuer","Teaching material 2021","|LINK:https://github.com/zouharvi/uds-snlp-tutorial",,"snlp_tutorial.png"
"Fact Learning with Adaptive Color Palette: Effect of Stimuli-Independent Hints","Vilém Zouhar, Leander van Boven, Tianyi Li, Anjali Nair",2021,"|CODE:https://github.com/zouharvi/fact-learning-colors|REPORT:https://raw.githubusercontent.com/zouharvi/fact-learning-colors/main/meta/paper_vilem/Fact_Learning_with_Adaptive_Color_Palette.pdf","This paper focuses on fact learning and potential improvements via color feedback. In one setting, the users see a color based on the estimated difficulty by SlimStampen. In another setting, each stimulus is mapped to a random but constant color. We find that a key property of the task is the high individual variance which prevents statistically significant conclusions. The results however suggest that certain conditions can increase learning speed, though this improvement is not retained during testing. The results also change when viewed from the perspective of test accuracy or number of learned words.","fact_learning_colors.png"
"Hyperparameters of RNN Architectures for POS Tagging using Surface-Level BERT Embeddings",,2020,"|CODE:https://github.com/zouharvi/rnn-bert-pos|PAPER:https://github.com/zouharvi/rnn-bert-pos/blob/main/meta/paper.pdf","Contextual embeddings from pretrained BERTmodels have been useful in a variety of natural language processing tasks. This paper focuses on one of the basic of those tasks, Part of Speech tagging, and compares several simple recurrent neural network models (vanilla RNN, GRU, LSTM) and their hyperparameters (hidden state size, recurrent layers and dropout, bidirectional, dense layers). While stacking recurrent layers or densely connected output layers negatively affects the performance, adding bidirectionality and increasing hidden state size improve it significantly.",
"SlowAlign",,2020,"|CODE:https://github.com/zouharvi/SlowAlign|REPORT:https://raw.githubusercontent.com/zouharvi/SlowAlign/main/meta/REPORT.pdf","Word alignment is a well-established task, which found its use mostly in PBMT. This report presents SlowAlign, a system combining multiple hard alignment extracting strategies, which are determined by a small number of parameters. The main functionalities of SlowAlign are (1) heuristic parameter estimation in a supervised fashion using gridsearch, (2) combination of multiple soft alignments and (3) data-less alignment based on diagonal alignment, Levenstein distance and blurring.","slowalign.png"
"Slow Align Displayer",,2020,"|LINK:https://vilda.net/s/slowalign/|CODE:https://github.com/zouharvi/SlowAlignDisplayer","Creates quick graphs given word alignment.","slowalign_displayer.png"
"MosQEto","Vilém Zouhar, Ondřej Měkota",2019,"|CODE:https://github.com/zouharvi/MosQEto|LINK:https://raw.githubusercontent.com/zouharvi/MosQEto/master/report/MosQEto.pdf","Word level quality estimation (QE) of machine translation is a task aiming to identify badly translated words and spaces between words. We propose a framework for experiment replication of QE systems MosQEto. We were also experimenting with several methods, trying to improve the quality estimation of systems implemented in OpenKiwi by smartly preprocessing and synthesizing training data.",
"Dorfromantik solver","",2023,"|TOOL:https://vilda.net/s/dorfromantik-solver|CODE:https://github.com/zouharvi/dorfromantik-solver","A tool to help with a small game.","dorfromantik.png"
"Call for Menza",,2019,"|CODE:https://github.com/zouharvi/cfm","Aggregator of daily menus around Charles University. Unmaintained since I moved out of Prague.",
"SMAKE","Vilém Zouhar, Petr Houška",2019,"|CODE:https://github.com/zouharvi/SMAKE","Simple Markable And Keyword Extraction.",
"TNTranslator",,2019,"|CODE:https://github.com/zouharvi/TNTranslator","Translation inspector for n-best list navigator.",
"A Collection of Machine Learning Excercises","Martin Holub, Barbora Vidová Hladká, Vilém Zouhar","Teaching material 2018","|LINK:https://ufal.mff.cuni.cz/courses/npfl054",,
"ZimaDB","Vilém Zouhar, Petr Chmel",2018,"|CODE:https://github.com/zouharvi/ZimaDB","SQLite-like database implementation from scratch.",
"ASM Hell",,2017,"|CODE:https://github.com/zouharvi/asm-hell|DEMO:https://zouharvi.itch.io/asm-hell","Learn basic assembly instructions through a game (LD41 submission).","asm_hell.png"
"Prolog KNN",,2017,"|CODE:https://github.com/zouharvi/prolog-knn","Implementation of kNN in Prolog, a language the least suited for this.",
